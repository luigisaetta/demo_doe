# parameters for user interface
[ui]
add_references = true
do_streaming = true
hello_msg = "Hello, how can I assist you?"

# title = "AI Assistant with LangChain ðŸ¦œ"
title = "AI Assistant for DOE Dubai"
verbose = false

# enable tracing with langsmith
[tracing]
enable = false
langchain_project = "workshop-1"

[text_splitting]
books_dir = "./books_med"
chunk_overlap = 50
chunk_size = 1500

[embeddings]
embed_model_type = "OCI"

[embeddings.oci]
embed_batch_size = 90
embed_endpoint = "https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com"
embed_model = "cohere.embed-multilingual-v3.0"

[embeddings.cohere]

# vector store
# store_type: OPENSEARCH, 23AI
[vector_store]
collection_name = "DOE_DUBAI2"
store_type = "23AI"

[vector_store.23ai]
embeddings_bit = 32

[reranker]
add_reranker = false

[retriever]
top_k = 8
top_n = 6

# general llm
[llm]
max_tokens = 2048
model_type = "OCI"
temperature = 0
top_k = 1
top_p = 1

[llm.oci]
# FRA
endpoint = "https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com"

# llm_model = "cohere.command-r-16k"
# llm_model = "cohere.command-r-plus"
llm_model = "meta.llama-3-70b-instruct"


